"""
Docker infrastructure backend for DAZZLE.

Generates local development infrastructure using Docker Compose.
"""

from pathlib import Path
from typing import Any

from ..core import ir
from ..core.errors import BackendError
from ..core.infra_analyzer import (
    InfraRequirements,
    analyze_infra_requirements,
    get_required_env_vars,
)
from ..core.manifest import DockerConfig
from . import Backend, BackendCapabilities


class DockerStack(Backend):
    """
    Docker stack for local development infrastructure.

    Creates:
    - Dockerfile for the application
    - docker-compose.yaml with all required services
    - .dockerignore
    - dev.env.example
    - README.md with usage instructions
    """

    def generate(
        self, appspec: ir.AppSpec, output_dir: Path, docker_config: DockerConfig = None, **options
    ) -> None:
        """
        Generate Docker infrastructure for local development.

        Args:
            appspec: Application specification from IR
            output_dir: Output directory (typically infra/docker/)
            docker_config: Docker configuration from manifest
            **options: Additional options

        Raises:
            BackendError: If generation fails
        """
        try:
            # Ensure output directory exists
            output_dir.mkdir(parents=True, exist_ok=True)

            # Use default config if not provided
            if docker_config is None:
                docker_config = DockerConfig()

            # Analyze infrastructure requirements
            requirements = analyze_infra_requirements(appspec)

            # Generate all artifacts
            self._generate_dockerfile(output_dir, appspec, docker_config, requirements)
            self._generate_compose(output_dir, appspec, docker_config, requirements)
            self._generate_dockerignore(output_dir)
            self._generate_dev_env_example(output_dir, requirements)
            self._generate_readme(output_dir, appspec, requirements)

        except Exception as e:
            if isinstance(e, BackendError):
                raise
            raise BackendError(f"Failed to generate Docker infrastructure: {e}") from e

    def get_capabilities(self) -> BackendCapabilities:
        return BackendCapabilities(
            name="docker",
            description="Generate Docker Compose setup for local development",
            output_formats=["dockerfile", "compose"],
            supports_incremental=False,
            requires_config=False,
        )

    def _generate_dockerfile(
        self,
        output_dir: Path,
        appspec: ir.AppSpec,
        config: DockerConfig,
        requirements: InfraRequirements,
    ) -> None:
        """Generate Dockerfile for the application."""
        dockerfile_content = f'''# Generated by DAZZLE - {appspec.title or appspec.name}
FROM {config.base_image}

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    postgresql-client \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Expose application port
EXPOSE {config.port}

# Default command (can be overridden in compose)
CMD ["python", "-m", "uvicorn", "main:app", "--host", "0.0.0.0", "--port", "{config.port}"]
'''

        (output_dir / "Dockerfile").write_text(dockerfile_content)

    def _generate_compose(
        self,
        output_dir: Path,
        appspec: ir.AppSpec,
        config: DockerConfig,
        requirements: InfraRequirements,
    ) -> None:
        """Generate docker-compose.yaml with all required services."""
        services: dict[str, Any] = {}

        # App service
        image_name = config.image_name or appspec.name.replace("_", "-")
        services["app"] = {
            "build": ".",
            "image": f"{image_name}:latest",
            "container_name": f"{image_name}_app",
            "ports": [f"{config.port}:{config.port}"],
            "env_file": ".env",
            "environment": {
                "APP_NAME": appspec.name,
                "APP_ENV": "development",
            },
            "depends_on": [],
            "volumes": [
                ".:/app",
                "/app/__pycache__",
            ],
        }

        # Database service
        if requirements.needs_database:
            db_name = appspec.name.replace("-", "_")
            services["db"] = {
                "image": "postgres:15-alpine",
                "container_name": f"{image_name}_db",
                "environment": {
                    "POSTGRES_DB": db_name,
                    "POSTGRES_USER": "dazzle",
                    "POSTGRES_PASSWORD": "dazzle_dev_password",
                },
                "ports": ["5432:5432"],
                "volumes": [
                    "postgres_data:/var/lib/postgresql/data",
                ],
                "healthcheck": {
                    "test": ["CMD-SHELL", "pg_isready -U dazzle"],
                    "interval": "10s",
                    "timeout": "5s",
                    "retries": 5,
                },
            }
            services["app"]["depends_on"].append("db")
            services["app"]["environment"].update(
                {
                    "DATABASE_HOST": "db",
                    "DATABASE_PORT": "5432",
                    "DATABASE_NAME": db_name,
                    "DATABASE_USER": "dazzle",
                    "DATABASE_PASSWORD": "dazzle_dev_password",
                }
            )

        # Redis service (for cache and/or queue)
        if requirements.needs_cache or requirements.needs_queue:
            services["redis"] = {
                "image": "redis:7-alpine",
                "container_name": f"{image_name}_redis",
                "ports": ["6379:6379"],
                "volumes": [
                    "redis_data:/data",
                ],
                "healthcheck": {
                    "test": ["CMD", "redis-cli", "ping"],
                    "interval": "10s",
                    "timeout": "5s",
                    "retries": 5,
                },
            }
            services["app"]["depends_on"].append("redis")
            services["app"]["environment"].update(
                {
                    "REDIS_HOST": "redis",
                    "REDIS_PORT": "6379",
                }
            )

        # Worker service (for async processing)
        if requirements.needs_workers:
            services["worker"] = {
                "build": ".",
                "image": f"{image_name}:latest",
                "container_name": f"{image_name}_worker",
                "env_file": ".env",
                "command": "python -m celery -A worker worker --loglevel=info",
                "depends_on": services["app"]["depends_on"].copy(),
                "environment": services["app"]["environment"].copy(),
                "volumes": services["app"]["volumes"].copy(),
            }

        # Build compose file
        compose_content = {
            "version": "3.8",
            "services": services,
        }

        # Add volumes section if needed
        volumes = []
        if requirements.needs_database:
            volumes.append("postgres_data")
        if requirements.needs_cache or requirements.needs_queue:
            volumes.append("redis_data")

        if volumes:
            compose_content["volumes"] = dict.fromkeys(volumes)

        # Write YAML
        yaml_content = self._dict_to_yaml(compose_content)
        (output_dir / "compose.yaml").write_text(yaml_content)

    def _dict_to_yaml(self, data: dict[str, Any], indent: int = 0) -> str:
        """Convert dict to YAML format (simple implementation)."""
        lines = []
        indent_str = "  " * indent

        for key, value in data.items():
            if value is None:
                lines.append(f"{indent_str}{key}:")
            elif isinstance(value, dict):
                lines.append(f"{indent_str}{key}:")
                lines.append(self._dict_to_yaml(value, indent + 1))
            elif isinstance(value, list):
                lines.append(f"{indent_str}{key}:")
                for item in value:
                    if isinstance(item, dict):
                        lines.append(f"{indent_str}  -")
                        for k, v in item.items():
                            lines.append(f"{indent_str}    {k}: {self._yaml_value(v)}")
                    else:
                        lines.append(f"{indent_str}  - {self._yaml_value(item)}")
            else:
                lines.append(f"{indent_str}{key}: {self._yaml_value(value)}")

        return "\n".join(lines)

    def _yaml_value(self, value: Any) -> str:
        """Format a value for YAML."""
        if isinstance(value, str):
            # Quote if contains special characters
            if ":" in value or "#" in value or value.startswith("$"):
                return f'"{value}"'
            return value
        elif isinstance(value, bool):
            return "true" if value else "false"
        else:
            return str(value)

    def _generate_dockerignore(self, output_dir: Path) -> None:
        """Generate .dockerignore file."""
        dockerignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
env/
ENV/
.venv

# Build
build/
dist/
*.egg-info/

# Testing
.pytest_cache/
.coverage
htmlcov/

# IDE
.vscode/
.idea/
*.swp
*.swo

# Git
.git/
.gitignore

# Docker
.dockerignore
Dockerfile
compose.yaml

# Dazzle
.dazzle/
dsl/
dazzle.toml

# Misc
.DS_Store
*.log
.env
.env.*
!.env.example
"""

        (output_dir / ".dockerignore").write_text(dockerignore_content)

    def _generate_dev_env_example(
        self,
        output_dir: Path,
        requirements: InfraRequirements,
    ) -> None:
        """Generate dev.env.example file."""
        get_required_env_vars(requirements)

        lines = [
            "# Development environment variables",
            "# Copy this file to .env and adjust values as needed",
            "",
        ]

        # Group variables by category
        if requirements.needs_database:
            lines.extend(
                [
                    "# Database",
                    "DATABASE_HOST=db",
                    "DATABASE_PORT=5432",
                    "DATABASE_NAME=app_db",
                    "DATABASE_USER=dazzle",
                    "DATABASE_PASSWORD=dazzle_dev_password",
                    "",
                ]
            )

        if requirements.needs_cache or requirements.needs_queue:
            lines.extend(
                [
                    "# Redis",
                    "REDIS_HOST=redis",
                    "REDIS_PORT=6379",
                    "",
                ]
            )

        if requirements.needs_storage:
            lines.extend(
                [
                    "# Storage",
                    "STORAGE_BUCKET=dev-bucket",
                    "STORAGE_REGION=us-east-1",
                    "STORAGE_ACCESS_KEY=your-key",
                    "STORAGE_SECRET_KEY=your-secret",
                    "",
                ]
            )

        if requirements.needs_webhooks:
            lines.extend(
                [
                    "# Webhooks",
                    "WEBHOOK_SECRET=your-webhook-secret",
                    "WEBHOOK_URL=http://localhost:8000/webhooks",
                    "",
                ]
            )

        lines.extend(
            [
                "# Application",
                "APP_ENV=development",
                "APP_DEBUG=false  # Set to 'true' for development",
                "SECRET_KEY=dev-secret-key-change-in-production",
            ]
        )

        (output_dir / "dev.env.example").write_text("\n".join(lines) + "\n")

    def _generate_readme(
        self,
        output_dir: Path,
        appspec: ir.AppSpec,
        requirements: InfraRequirements,
    ) -> None:
        """Generate README with Docker usage instructions."""
        services = ["application"]
        if requirements.needs_database:
            services.append("PostgreSQL database")
        if requirements.needs_cache:
            services.append("Redis cache")
        if requirements.needs_queue:
            services.append("Redis queue")
        if requirements.needs_workers:
            services.append("background workers")

        services_list = "\n".join(f"- {s}" for s in services)

        readme_content = f"""# Docker Infrastructure for {appspec.title or appspec.name}

Generated by DAZZLE infrastructure backend.

## Services

This Docker Compose setup includes:

{services_list}

## Quick Start

1. **Copy environment file:**
   ```bash
   cp dev.env.example .env
   ```

2. **Start all services:**
   ```bash
   docker compose up -d
   ```

3. **View logs:**
   ```bash
   docker compose logs -f
   ```

4. **Stop services:**
   ```bash
   docker compose down
   ```

## Service URLs

- Application: http://localhost:{requirements.entity_count and "8000" or "8000"}
"""

        if requirements.needs_database:
            readme_content += """- Database: postgresql://dazzle:dazzle_dev_password@localhost:5432/app_db
"""

        if requirements.needs_cache or requirements.needs_queue:
            readme_content += """- Redis: redis://localhost:6379
"""

        readme_content += """
## Development Workflow

### Running migrations
```bash
docker compose exec app python manage.py migrate
```

### Running tests
```bash
docker compose exec app pytest
```

### Accessing database
```bash
docker compose exec db psql -U dazzle -d app_db
```

### Viewing worker logs
```bash
docker compose logs -f worker
```

## Rebuilding

After changing dependencies:
```bash
docker compose build
docker compose up -d
```

## Troubleshooting

### Reset database
```bash
docker compose down -v
docker compose up -d
```

### Rebuild from scratch
```bash
docker compose down -v
docker compose build --no-cache
docker compose up -d
```

---

Generated by DAZZLE Docker backend
"""

        (output_dir / "README.md").write_text(readme_content)


__all__ = ["DockerStack"]
